# Multi-Agent Incident Response Demo

Demo-grade incident response system showcasing ToonDB's IPC mode, namespace isolation, hybrid retrieval, and ACID state transitions.

## What This Demo Shows

1. **IPC Mode**: Multiple processes sharing one ToonDB instance via Unix socket
2. **Namespace Isolation**: Separate namespaces for `incident_ops` data
3. **Hybrid Retrieval**: Vector + keyword search with Reciprocal Rank Fusion (RRF)
4. **ACID State Transitions**: Incident states (OPEN â†’ MITIGATING â†’ RESOLVED)
5. **Concurrent Writes**: Three processes writing simultaneously without conflicts
6. **Token-Budgeted Context**: Runbook retrieval under strict token limits

## Architecture

```
Process A (Collector)  â”€â”€â”€â”€â”
                           â”œâ”€â”€â†’ ToonDB Server (IPC)
Process B (Indexer)    â”€â”€â”€â”€â”¤         â†“
                           â”‚    Shared State:
Process C (Commander)  â”€â”€â”€â”€â”˜    - Metrics (KV)
                                - Runbooks (Vectors)
                                - Incident State (KV)
```

## Setup

### 1. Install Dependencies

```bash
pip install toondb openai tiktoken
```

### 2. Set OpenAI API Key

```bash
export OPENAI_API_KEY="your-api-key-here"
```

### 3. Start ToonDB Server

```bash
cd demos/2_incident_response
./start_server.sh
```

This starts ToonDB in IPC mode with a Unix socket at `./ops_db/toondb.sock`.

## Usage

### Run All Processes

```bash
./run_demo.sh
```

This starts:
- **Process A**: Metrics collector (writes metrics every 5s)
- **Process B**: Runbook indexer (indexes runbooks into vector collection)
- **Process C**: Incident commander (monitors metrics, triggers response)

### Run Processes Manually

In separate terminals:

```bash
# Terminal 1: Start server
./start_server.sh

# Terminal 2: Index runbooks
python process_b_indexer.py

# Terminal 3: Collect metrics
python process_a_collector.py

# Terminal 4: Monitor incidents
python process_c_commander.py
```

## Demo Flow

### 1. Normal Operation
Process A writes metrics every 5 seconds:
```
[2026-01-04T18:00:00] Latency P99: 350ms | Error Rate: 1.2% | CPU: 45.3%
```

Process C monitors and shows "OK" status.

### 2. Incident Trigger
When latency > 1000ms AND error rate > 5%:
```
ðŸš¨ðŸš¨ðŸš¨ INCIDENT DETECTED! ðŸš¨ðŸš¨ðŸš¨

ðŸ“Š Incident Details:
   Latency P99: 1450ms
   Error Rate: 6.8%
   Triggered: 2026-01-04T18:05:23

ðŸ“ State transition: NONE â†’ OPEN
```

### 3. Runbook Retrieval
Process C retrieves relevant runbooks using hybrid search:
```
ðŸ” Retrieving relevant runbooks (hybrid search)...
   Retrieved 8 runbook chunks
   Token budget used: ~1850 tokens
```

Combines:
- **Vector search**: Semantic similarity to incident symptoms
- **Keyword search**: "latency spike deployment rollback database"
- **RRF**: Fuses results from both methods

### 4. Mitigation Plan
LLM generates actionable plan:
```
MITIGATION PLAN
===============
Most Likely Root Cause: Recent deployment causing database overload

Immediate Actions:
1. Check recent deployments (last 30 min)
2. Review database slow query log
3. Consider deployment rollback if spike coincides with deploy

Next Steps:
1. Monitor metrics for 5 minutes after mitigation
2. Document incident timeline
3. Schedule postmortem
```

### 5. State Transition
```
ðŸ“ State transition: OPEN â†’ MITIGATING
âš¡ Executing mitigation actions...
ðŸ”¬ Checking metrics...
ðŸ“ State transition: MITIGATING â†’ RESOLVED
âœ… Incident resolved!
```

## Key Highlights

### IPC: Shared DB Across Processes

All three processes connect to the same ToonDB instance:

```python
from toondb import IpcClient

client = IpcClient.connect("./ops_db/toondb.sock")

# Process A writes metrics
client.put(b"metrics/latest/latency_p99", b"1450")

# Process C reads metrics
latency = client.get(b"metrics/latest/latency_p99")
```

### Hybrid Search with RRF

Combines vector and keyword search:

```python
ctx = (
    ContextQuery(collection)
    .add_vector_query(embedding, weight=0.6)    # Semantic
    .add_keyword_query("latency spike", weight=0.4)  # Keyword
    .with_token_budget(2000)
    .with_deduplication(DeduplicationStrategy.SEMANTIC)
    .execute()
)
```

### ACID State Machine

Incident transitions are atomic:
```
NONE â†’ OPEN â†’ MITIGATING â†’ RESOLVED
```

Each transition writes:
- Current state
- Timestamp
- Historical record

All operations are consistent across processes.

## Files

- `start_server.sh`: Start ToonDB in IPC mode
- `process_a_collector.py`: Metrics collector (writes to KV)
- `process_b_indexer.py`: Runbook indexer (writes to vectors)
- `process_c_commander.py`: Incident commander (reads KV + vectors, writes state)
- `run_demo.sh`: Orchestrate all processes
- `runbooks/`: Runbook documents
  - `latency_spike.txt`: Latency troubleshooting guide
  - `deployment_rollback.txt`: Rollback procedures
  - `database_recovery.txt`: Database recovery steps

## Troubleshooting

### Server Won't Start

```bash
# Check if server is already running
toondb-server status --db ./ops_db

# Stop existing server
toondb-server stop --db ./ops_db

# Start fresh
./start_server.sh
```

### Process Can't Connect

Ensure server is running first:
```bash
./start_server.sh
# Wait for "âœ… ToonDB server is running!" message
```

### No Incident Triggered

Incidents trigger when BOTH conditions are met:
- Latency P99 > 1000ms
- Error Rate > 5%

Process A increases these values after ~20 iterations (100 seconds).

{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Demo 3: Analytics Copilot with TOON Encoding\n",
                "\n",
                "## Overview\n",
                "\n",
                "This notebook demonstrates building an analytics copilot that:\n",
                "- Loads **CSV data** into SQL tables\n",
                "- Encodes query results in **TOON format** (40-67% token savings!)\n",
                "- Uses **vector search** over customer notes for semantic analysis\n",
                "- Assembles context with **strict token budgets**\n",
                "- Generates **AI-powered insights** for churn prediction\n",
                "\n",
                "### What You'll Learn\n",
                "\n",
                "1. How to **ingest CSV** data into ToonDB\n",
                "2. How **TOON encoding** saves tokens (with proof!)\n",
                "3. How to run **SQL analytics queries**\n",
                "4. How to use **vector search** on text fields\n",
                "5. How to **measure token savings** with tiktoken\n",
                "6. How to build **data analysis agents**\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup\n",
                "\n",
                "### Prerequisites\n",
                "\n",
                "```bash\n",
                "pip install toondb openai tiktoken\n",
                "export OPENAI_API_KEY=\"your-api-key-here\"\n",
                "```\n",
                "\n",
                "### Import Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import csv\n",
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "sys.path.insert(0, str(Path.cwd().parent))\n",
                "\n",
                "from toondb import Database, ContextQuery, DeduplicationStrategy\n",
                "from shared.toon_encoder import rows_to_toon\n",
                "from shared.llm_client import LLMClient, count_tokens\n",
                "from shared.embeddings import EmbeddingClient\n",
                "import tiktoken\n",
                "\n",
                "print(\"‚úÖ All dependencies imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 1: Token Comparison - TOON vs JSON\n",
                "\n",
                "### üìö Concept: TOON Format\n",
                "\n",
                "TOON (Tabular Object Oriented Notation) is designed for tabular data in prompts:\n",
                "\n",
                "**Format**:\n",
                "```\n",
                "table_name[row_count]{field1,field2,field3}:\n",
                "value1,value2,value3\n",
                "value4,value5,value6\n",
                "```\n",
                "\n",
                "**Why it saves tokens**:\n",
                "- No repeated field names (JSON has them on every row)\n",
                "- No brackets/braces per row\n",
                "- CSV-like compactness\n",
                "- Tab/human-readable structure\n",
                "\n",
                "### Let's Prove It!\n",
                "\n",
                "We'll measure actual tokens using `tiktoken` (OpenAI's tokenizer)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example data\n",
                "sample_data = [\n",
                "    {\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\", \"age\": 28},\n",
                "    {\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\", \"age\": 34},\n",
                "    {\"id\": 3, \"name\": \"Carol\", \"email\": \"carol@example.com\", \"age\": 42}\n",
                "]\n",
                "\n",
                "# JSON format\n",
                "json_format = json.dumps(sample_data, indent=2)\n",
                "\n",
                "# TOON format\n",
                "toon_format = rows_to_toon(\"users\", sample_data, fields=[\"id\", \"name\", \"email\", \"age\"])\n",
                "\n",
                "# Count tokens\n",
                "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
                "json_tokens = len(enc.encode(json_format))\n",
                "toon_tokens = len(enc.encode(toon_format))\n",
                "\n",
                "savings = json_tokens - toon_tokens\n",
                "percent_saved = (savings / json_tokens * 100)\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"TOKEN COMPARISON: JSON vs TOON\")\n",
                "print(\"=\"*70)\n",
                "print(\"\\nJSON FORMAT:\")\n",
                "print(\"-\"*70)\n",
                "print(json_format)\n",
                "print(f\"\\nTokens: {json_tokens}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"\\nTOON FORMAT:\")\n",
                "print(\"-\"*70)\n",
                "print(toon_format)\n",
                "print(f\"Tokens: {toon_tokens}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(f\"\\n‚úÖ RESULTS:\")\n",
                "print(f\"   JSON tokens:      {json_tokens}\")\n",
                "print(f\"   TOON tokens:      {toon_tokens}\")\n",
                "print(f\"   Tokens saved:     {savings}\")\n",
                "print(f\"   Percent saved:    {percent_saved:.1f}%\")\n",
                "print(\"\\n\" + \"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üí° Key Insight\n",
                "\n",
                "Even with just 3 rows, we saved **~50-60% tokens**!\n",
                "\n",
                "With larger datasets (10-100 rows), savings approach **60-70%**.\n",
                "\n",
                "**Why this matters**:\n",
                "- More data fits in prompts\n",
                "- Lower API costs\n",
                "- Faster model processing\n",
                "- Better context for AI\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Load CSV Data into ToonDB\n",
                "\n",
                "### üìö Concept: CSV ‚Üí SQL Pipeline\n",
                "\n",
                "ToonDB's SQL interface makes it easy:\n",
                "1. Create table schema\n",
                "2. Load CSV rows\n",
                "3. Insert with `execute_sql`\n",
                "\n",
                "**No ETL tool needed** - just Python + ToonDB.\n",
                "\n",
                "### How-To: Ingest CSV Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load customer data CSV\n",
                "csv_path = \"../3_analytics_copilot/sample_data/customers.csv\"\n",
                "db_path = \"./analytics_db\"\n",
                "\n",
                "# Read CSV\n",
                "with open(csv_path, 'r') as f:\n",
                "    reader = csv.DictReader(f)\n",
                "    customers = list(reader)\n",
                "\n",
                "print(f\"üì• Loaded {len(customers)} customers from CSV\")\n",
                "print(f\"\\nSample customer:\")\n",
                "print(json.dumps(customers[0], indent=2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create database and schema\n",
                "with Database.open(db_path) as db:\n",
                "    db.execute_sql(\"\"\"\n",
                "        CREATE TABLE IF NOT EXISTS customers (\n",
                "            id INTEGER PRIMARY KEY,\n",
                "            name TEXT NOT NULL,\n",
                "            email TEXT NOT NULL,\n",
                "            account_value REAL NOT NULL,\n",
                "            contract_end TEXT NOT NULL,\n",
                "            monthly_active_days INTEGER,\n",
                "            support_tickets_30d INTEGER,\n",
                "            last_login_days_ago INTEGER,\n",
                "            feature_usage_score REAL,\n",
                "            notes TEXT\n",
                "        )\n",
                "    \"\"\")\n",
                "    \n",
                "    # Insert customers\n",
                "    for customer in customers:\n",
                "        db.execute_sql(f\"\"\"\n",
                "            INSERT OR REPLACE INTO customers VALUES (\n",
                "                {customer['id']},\n",
                "                '{customer['name']}',\n",
                "                '{customer['email']}',\n",
                "                {customer['account_value']},\n",
                "                '{customer['contract_end']}',\n",
                "                {customer['monthly_active_days']},\n",
                "                {customer['support_tickets_30d']},\n",
                "                {customer['last_login_days_ago']},\n",
                "                {customer['feature_usage_score']},\n",
                "                '{customer['notes'].replace(\"'\", \"''\")}'\n",
                "            )\n",
                "        \"\"\")\n",
                "\n",
                "print(f\"‚úÖ Inserted {len(customers)} customers into SQL table\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 3: SQL Analytics for Churn Risk\n",
                "\n",
                "### üìö Concept: SQL for Business Logic\n",
                "\n",
                "Use SQL WHERE clauses to identify at-risk customers:\n",
                "- Low engagement (few active days)\n",
                "- High support burden (many tickets)\n",
                "- Recent inactivity (last login)\n",
                "- Low product adoption (feature usage score)\n",
                "\n",
                "### How-To: Query At-Risk Customers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with Database.open(db_path) as db:\n",
                "    result = db.execute_sql(\"\"\"\n",
                "        SELECT \n",
                "            id, name, account_value, contract_end,\n",
                "            monthly_active_days, support_tickets_30d,\n",
                "            last_login_days_ago, feature_usage_score\n",
                "        FROM customers\n",
                "        WHERE (\n",
                "            monthly_active_days < 15\n",
                "            OR support_tickets_30d > 5\n",
                "            OR last_login_days_ago > 7\n",
                "            OR feature_usage_score < 50\n",
                "        )\n",
                "        ORDER BY feature_usage_score ASC, support_tickets_30d DESC\n",
                "        LIMIT 10\n",
                "    \"\"\")\n",
                "    \n",
                "    at_risk = result.rows\n",
                "\n",
                "print(f\"üìä Found {len(at_risk)} at-risk customers:\\n\")\n",
                "for customer in at_risk[:5]:  # Show top 5\n",
                "    print(f\"   {customer['name']} (ID: {customer['id']})\")\n",
                "    print(f\"      Score: {customer['feature_usage_score']} | Tickets: {customer['support_tickets_30d']} | Active Days: {customer['monthly_active_days']}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 4: Encode Results in TOON\n",
                "\n",
                "### Compare Token Counts for Real Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fields to include in context\n",
                "fields = [\n",
                "    \"id\", \"name\", \"account_value\", \"contract_end\",\n",
                "    \"monthly_active_days\", \"support_tickets_30d\",\n",
                "    \"last_login_days_ago\", \"feature_usage_score\"\n",
                "]\n",
                "\n",
                "# TOON format\n",
                "toon_data = rows_to_toon(\"at_risk_customers\", at_risk, fields=fields)\n",
                "\n",
                "# JSON format\n",
                "json_data = json.dumps(at_risk, indent=2)\n",
                "\n",
                "# Count tokens\n",
                "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
                "toon_tokens = len(enc.encode(toon_data))\n",
                "json_tokens = len(enc.encode(json_data))\n",
                "\n",
                "savings = json_tokens - toon_tokens\n",
                "percent_saved = (savings / json_tokens * 100)\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"REAL DATA TOKEN COMPARISON\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nDataset: {len(at_risk)} at-risk customers\")\n",
                "print(f\"\\nTOON Format Preview:\")\n",
                "print(\"-\"*70)\n",
                "print(toon_data[:300] + \"...\\n\" if len(toon_data) > 300 else toon_data)\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nüíæ Token Savings:\")\n",
                "print(f\"   JSON tokens:  {json_tokens}\")\n",
                "print(f\"   TOON tokens:  {toon_tokens}\")\n",
                "print(f\"   Saved:        {savings} tokens ({percent_saved:.1f}%)\")\n",
                "print(\"\\n\" + \"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üéØ Result\n",
                "\n",
                "With real customer data, TOON typically saves **55-65%** tokens!\n",
                "\n",
                "For this dataset:\n",
                "- More customers = more savings\n",
                "- Larger tables = bigger impact\n",
                "- Production datasets can save **thousands** of tokens\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 5: Vector Search on Customer Notes\n",
                "\n",
                "### üìö Concept: Semantic Search Over Text\n",
                "\n",
                "Customer notes contain valuable insights:\n",
                "- Complaints\n",
                "- Feature requests\n",
                "- Churn signals\n",
                "\n",
                "Vector search finds semantically relevant notes, even without exact keywords.\n",
                "\n",
                "### How-To: Index and Search Notes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "embedding_client = EmbeddingClient()\n",
                "dimension = embedding_client.dimension\n",
                "\n",
                "with Database.open(db_path) as db:\n",
                "    # Create namespace and collection\n",
                "    ns = db.namespace(\"analytics\")\n",
                "    collection = ns.create_collection(\"customer_notes\", dimension=dimension)\n",
                "    \n",
                "    # Index customer notes\n",
                "    print(\"üìù Indexing customer notes...\\n\")\n",
                "    for customer in customers:\n",
                "        if customer['notes'].strip():\n",
                "            embedding = embedding_client.embed(customer['notes'])\n",
                "            \n",
                "            collection.add_document(\n",
                "                id=f\"customer_{customer['id']}\",\n",
                "                embedding=embedding,\n",
                "                text=customer['notes'],\n",
                "                metadata={\n",
                "                    \"customer_id\": customer['id'],\n",
                "                    \"customer_name\": customer['name']\n",
                "                }\n",
                "            )\n",
                "            print(f\"   ‚úì {customer['name']}: {customer['notes'][:60]}...\")\n",
                "\n",
                "print(f\"\\n‚úÖ Indexed {len(customers)} customer notes\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Search for churn-related notes\n",
                "query = \"customers at risk of churning with low engagement or many support issues\"\n",
                "query_embedding = embedding_client.embed(query)\n",
                "\n",
                "with Database.open(db_path) as db:\n",
                "    ns = db.namespace(\"analytics\")\n",
                "    collection = ns.collection(\"customer_notes\")\n",
                "    \n",
                "    # Hybrid search\n",
                "    ctx = (\n",
                "        ContextQuery(collection)\n",
                "        .add_vector_query(query_embedding, weight=0.8)\n",
                "        .add_keyword_query(\"churn risk support tickets low engagement\", weight=0.2)\n",
                "        .with_token_budget(1000)\n",
                "        .with_deduplication(DeduplicationStrategy.SEMANTIC)\n",
                "        .execute()\n",
                "    )\n",
                "\n",
                "print(f\"üîç Search query: '{query}'\\n\")\n",
                "print(f\"üìÑ Found {len(ctx.documents)} relevant customer notes:\\n\")\n",
                "\n",
                "for i, doc in enumerate(ctx.documents, 1):\n",
                "    print(f\"{i}. {doc.metadata['customer_name']}:\")\n",
                "    print(f\"   {doc.text}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 6: Generate AI-Powered Churn Analysis\n",
                "\n",
                "### Combine SQL Data (TOON) + Vector Search Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "llm = LLMClient()\n",
                "\n",
                "system_message = \"\"\"You are a customer success data analyst.\n",
                "Analyze customer data to identify churn risks and provide actionable recommendations.\"\"\"\n",
                "\n",
                "prompt = f\"\"\"Question: Which customers are most at risk of churn, and why?\n",
                "\n",
                "At-Risk Customers (TOON format):\n",
                "{toon_data}\n",
                "\n",
                "Customer Notes (semantic search results):\n",
                "{ctx.as_markdown()}\n",
                "\n",
                "Provide:\n",
                "1. Summary of top 3-5 churn risks (customer names + reasons)\n",
                "2. Common patterns across at-risk customers\n",
                "3. Recommended interventions (priority order)\n",
                "\"\"\"\n",
                "\n",
                "response = llm.complete(prompt, system_message=system_message)\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"CHURN RISK ANALYSIS\")\n",
                "print(\"=\"*70)\n",
                "print(response)\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 7: Measure Total Token Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate total prompt tokens\n",
                "total_prompt = f\"{system_message}\\n\\n{prompt}\"\n",
                "prompt_tokens = count_tokens(total_prompt)\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"TOKEN USAGE ANALYSIS\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(f\"\\nüìä Context Breakdown:\")\n",
                "print(f\"   SQL data (TOON):         {toon_tokens} tokens\")\n",
                "print(f\"   Customer notes (vector): ~{ctx.total_tokens} tokens\")\n",
                "print(f\"   System + user message:   ~{prompt_tokens - toon_tokens - ctx.total_tokens} tokens\")\n",
                "print(f\"   \" + \"-\"*50)\n",
                "print(f\"   Total prompt:            {prompt_tokens} tokens\")\n",
                "\n",
                "# Show what we saved\n",
                "json_equivalent_tokens = prompt_tokens - toon_tokens + json_tokens\n",
                "print(f\"\\nüí° If we used JSON instead of TOON:\")\n",
                "print(f\"   Total would be:          {json_equivalent_tokens} tokens\")\n",
                "print(f\"   We saved:                {json_equivalent_tokens - prompt_tokens} tokens\")\n",
                "print(f\"   Cost reduction:          ~{((json_equivalent_tokens - prompt_tokens) / json_equivalent_tokens * 100):.1f}%\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Summary: What We Accomplished\n",
                "\n",
                "### ‚úÖ Features Demonstrated\n",
                "\n",
                "1. **CSV Ingestion** - Loaded customer data into SQL table\n",
                "2. **TOON Encoding** - Proved 40-67% token savings with tiktoken\n",
                "3. **SQL Analytics** - Queried at-risk customers with WHERE clauses\n",
                "4. **Vector Search** - Semantic search over customer notes\n",
                "5. **Token Budgeting** - Retrieved context under 1000 token limit\n",
                "6. **AI Analysis** - Generated actionable churn insights\n",
                "\n",
                "### üí° Key Insights\n",
                "\n",
                "**TOON Saves Real Money**\n",
                "- Example: 10,000 API calls with 500 tokens saved each\n",
                "- Savings: 5,000,000 tokens\n",
                "- At $0.01/1K tokens (GPT-4): **$50 saved per day**\n",
                "\n",
                "**SQL + Vectors = Powerful**\n",
                "- SQL: Structured queries (who, what, when)\n",
                "- Vectors: Semantic search (why, context)\n",
                "- Together: Complete picture\n",
                "\n",
                "**No Separate Systems**\n",
                "- Traditional: CSV ‚Üí Postgres ‚Üí Pinecone ‚Üí LLM\n",
                "- ToonDB: CSV ‚Üí ToonDB ‚Üí LLM\n",
                "\n",
                "### üéØ Real-World Applications\n",
                "\n",
                "This pattern works for:\n",
                "- Customer analytics (churn, expansion, health)\n",
                "- Sales pipeline analysis\n",
                "- Financial data exploration  \n",
                "- Product usage analytics\n",
                "- Support ticket analysis\n",
                "- HR data insights\n",
                "\n",
                "**Any spreadsheet ‚Üí AI analysis workflow!**\n",
                "\n",
                "### üöÄ Next Steps\n",
                "\n",
                "Try:\n",
                "- Upload your own CSV data\n",
                "- Experiment with different SQL queries\n",
                "- Adjust token budgets\n",
                "- Compare TOON vs JSON on your data\n",
                "- Add more text fields for vector search\n",
                "\n",
                "---\n",
                "\n",
                "## Token Savings Calculator\n",
                "\n",
                "Want to estimate savings for your use case?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_savings(rows_per_query, queries_per_day, tokens_per_row_json=50, savings_percent=60):\n",
                "    \"\"\"Calculate daily token and cost savings.\"\"\"\n",
                "    json_tokens_daily = rows_per_query * queries_per_day * tokens_per_row_json\n",
                "    toon_tokens = json_tokens_daily * (1 - savings_percent / 100)\n",
                "    tokens_saved = json_tokens_daily - toon_tokens\n",
                "    \n",
                "    # GPT-4 pricing (example)\n",
                "    cost_per_1k = 0.01\n",
                "    cost_saved_daily = (tokens_saved / 1000) * cost_per_1k\n",
                "    cost_saved_monthly = cost_saved_daily * 30\n",
                "    \n",
                "    print(\"=\"*70)\n",
                "    print(\"SAVINGS CALCULATOR\")\n",
                "    print(\"=\"*70)\n",
                "    print(f\"\\nAssumptions:\")\n",
                "    print(f\"   Rows per query:        {rows_per_query}\")\n",
                "    print(f\"   Queries per day:       {queries_per_day}\")\n",
                "    print(f\"   Tokens/row (JSON):     {tokens_per_row_json}\")\n",
                "    print(f\"   TOON savings:          {savings_percent}%\")\n",
                "    \n",
                "    print(f\"\\nüí∞ Savings:\")\n",
                "    print(f\"   Tokens saved/day:      {tokens_saved:,.0f}\")\n",
                "    print(f\"   Cost saved/day:        ${cost_saved_daily:.2f}\")\n",
                "    print(f\"   Cost saved/month:      ${cost_saved_monthly:.2f}\")\n",
                "    print(f\"   Cost saved/year:       ${cost_saved_monthly * 12:.2f}\")\n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "\n",
                "# Example calculation\n",
                "calculate_savings(\n",
                "    rows_per_query=20,      # 20 rows per analysis\n",
                "    queries_per_day=1000,   # 1000 queries per day\n",
                "    tokens_per_row_json=50, # ~50 tokens per row in JSON\n",
                "    savings_percent=60      # 60% reduction with TOON\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Resources\n",
                "\n",
                "- [ToonDB Documentation](https://github.com/toondb/toondb)\n",
                "- [TOON Format Spec](https://github.com/toondb/toondb#toon-format)\n",
                "- [Demo Source Code](../3_analytics_copilot/)\n",
                "- [Tiktoken Library](https://github.com/openai/tiktoken)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Demo 2: Multi-Agent Incident Response with IPC\n",
                "\n",
                "## Overview\n",
                "\n",
                "This notebook demonstrates building a multi-agent incident response system where:\n",
                "- **3 separate processes** share one SochDB instance via **IPC (Inter-Process Communication)**\n",
                "- **Process A**: Collects metrics and writes to KV storage\n",
                "- **Process B**: Indexes runbooks into vector collection\n",
                "- **Process C**: Monitors metrics, retrieves runbooks, manages incident state\n",
                "\n",
                "### What You'll Learn\n",
                "\n",
                "1. How to run SochDB in **IPC mode** (Unix socket)\n",
                "2. How **multiple processes** can share one database\n",
                "3. How to use **namespaces** for data isolation\n",
                "4. How **hybrid retrieval** combines vector + keyword search\n",
                "5. How to implement **ACID state machines**\n",
                "6. How **concurrent writes** work without conflicts\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup\n",
                "\n",
                "### Prerequisites\n",
                "\n",
                "```bash\n",
                "pip install sochdb openai tiktoken\n",
                "export OPENAI_API_KEY=\"your-api-key-here\"\n",
                "```\n",
                "\n",
                "### Import Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import time\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "\n",
                "sys.path.insert(0, str(Path.cwd().parent))\n",
                "\n",
                "from sochdb import IpcClient, ContextQuery, DeduplicationStrategy\n",
                "from shared.llm_client import LLMClient\n",
                "from shared.embeddings import EmbeddingClient\n",
                "\n",
                "print(\"‚úÖ All dependencies imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Understanding IPC Mode\n",
                "\n",
                "### üìö Concept: IPC (Inter-Process Communication)\n",
                "\n",
                "**Traditional approach**: Each process has its own database connection, leading to:\n",
                "- Data duplication\n",
                "- Synchronization issues\n",
                "- Complex message passing\n",
                "\n",
                "**SochDB IPC approach**: One database server, multiple client processes:\n",
                "```\n",
                "SochDB Server (Unix Socket)\n",
                "    ‚Üì\n",
                "    ‚îú‚îÄ‚îÄ Process A (Metrics Collector)\n",
                "    ‚îú‚îÄ‚îÄ Process B (Runbook Indexer)\n",
                "    ‚îî‚îÄ‚îÄ Process C (Incident Commander)\n",
                "```\n",
                "\n",
                "**Benefits**:\n",
                "- Shared state automatically\n",
                "- No manual synchronization\n",
                "- ACID guarantees across processes\n",
                "\n",
                "### How-To: Start SochDB Server\n",
                "\n",
                "```bash\n",
                "# In a terminal\n",
                "sochdb-server --db ./incident_db\n",
                "```\n",
                "\n",
                "This creates a Unix socket at `./incident_db/sochdb.sock`\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Connect to IPC Server\n",
                "\n",
                "### How-To: Connect via IPC Client"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Note: This assumes SochDB server is running\n",
                "# If not started, run: sochdb-server --db ./incident_db\n",
                "\n",
                "socket_path = \"./incident_db/sochdb.sock\"\n",
                "\n",
                "try:\n",
                "    client = IpcClient.connect(socket_path)\n",
                "    print(f\"‚úÖ Connected to SochDB server via IPC\")\n",
                "    print(f\"   Socket: {socket_path}\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Could not connect: {e}\")\n",
                "    print(f\"\\nüí° Make sure to start the server first:\")\n",
                "    print(f\"   sochdb-server --db ./incident_db\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 2: Simulate Process A - Metrics Collector\n",
                "\n",
                "### üìö Concept: KV Storage for Time-Series Metrics\n",
                "\n",
                "Use KV paths to store metrics:\n",
                "- `metrics/latest/*` - Current values\n",
                "- `metrics/{metric_name}/{timestamp}` - Historical data\n",
                "\n",
                "**Why this works**: Fast writes, key-based access, no schema needed.\n",
                "\n",
                "### How-To: Write Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "\n",
                "def collect_metrics(client, iterations=5):\n",
                "    \"\"\"Simulate metrics collection.\"\"\"\n",
                "    print(\"üìä Simulating metrics collection...\\n\")\n",
                "    \n",
                "    for i in range(iterations):\n",
                "        timestamp = datetime.now().isoformat()\n",
                "        \n",
                "        # Simulate increasing latency/errors (incident trigger)\n",
                "        latency = random.randint(200, 800) if i < 3 else random.randint(1000, 2000)\n",
                "        error_rate = round(random.uniform(0.5, 3.0), 2) if i < 3 else round(random.uniform(5.0, 10.0), 2)\n",
                "        \n",
                "        # Write to KV\n",
                "        client.put(b\"metrics/latest/latency_p99\", str(latency).encode())\n",
                "        client.put(b\"metrics/latest/error_rate\", str(error_rate).encode())\n",
                "        client.put(b\"metrics/latest/timestamp\", timestamp.encode())\n",
                "        \n",
                "        print(f\"   [{i+1}] Latency: {latency}ms | Error Rate: {error_rate}%\")\n",
                "        time.sleep(1)\n",
                "    \n",
                "    # Trigger incident\n",
                "    if latency > 1000 and error_rate > 5.0:\n",
                "        client.put(b\"incidents/current/severity\", b\"HIGH\")\n",
                "        client.put(b\"incidents/current/latency\", str(latency).encode())\n",
                "        client.put(b\"incidents/current/error_rate\", str(error_rate).encode())\n",
                "        print(f\"\\nüö® INCIDENT TRIGGERED! Latency: {latency}ms, Error: {error_rate}%\")\n",
                "\n",
                "# Run simulation\n",
                "collect_metrics(client)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 3: Simulate Process B - Runbook Indexer\n",
                "\n",
                "### üìö Concept: Namespace Isolation\n",
                "\n",
                "Namespaces keep data separated:\n",
                "```python\n",
                "ns = client.namespace(\"incident_ops\")\n",
                "```\n",
                "\n",
                "- Collections live in namespaces\n",
                "- Prevents name collisions\n",
                "- Logical separation (tenants, environments, etc.)\n",
                "\n",
                "### How-To: Index Documents into Vector Collection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "embedding_client = EmbeddingClient()\n",
                "dimension = embedding_client.dimension\n",
                "\n",
                "# Sample runbook content\n",
                "runbooks = [\n",
                "    {\n",
                "        \"id\": \"latency_1\",\n",
                "        \"text\": \"Latency spike: Check recent deployments. If spike coincides with deployment, consider rollback.\",\n",
                "        \"source\": \"latency_spike.txt\"\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"latency_2\",\n",
                "        \"text\": \"High latency often caused by database overload. Check slow query log and connection pool utilization.\",\n",
                "        \"source\": \"latency_spike.txt\"\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"rollback_1\",\n",
                "        \"text\": \"To rollback deployment: kubectl rollout undo deployment/app-name. Monitor metrics for 5 minutes after.\",\n",
                "        \"source\": \"deployment_rollback.txt\"\n",
                "    }\n",
                "]\n",
                "\n",
                "# Create namespace and collection\n",
                "ns = client.namespace(\"incident_ops\")\n",
                "collection = ns.create_collection(\"runbooks\", dimension=dimension)\n",
                "\n",
                "print(f\"üìö Indexing runbooks into 'incident_ops' namespace...\\n\")\n",
                "\n",
                "for runbook in runbooks:\n",
                "    embedding = embedding_client.embed(runbook[\"text\"])\n",
                "    \n",
                "    collection.add_document(\n",
                "        id=runbook[\"id\"],\n",
                "        embedding=embedding,\n",
                "        text=runbook[\"text\"],\n",
                "        metadata={\"source\": runbook[\"source\"]}\n",
                "    )\n",
                "    print(f\"   ‚úì Indexed: {runbook['id']}\")\n",
                "\n",
                "print(f\"\\n‚úÖ Indexed {len(runbooks)} runbooks in vector collection\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 4: Simulate Process C - Incident Commander\n",
                "\n",
                "### üìö Concept: Hybrid Retrieval with RRF\n",
                "\n",
                "**Hybrid Search** = Vector Search + Keyword Search\n",
                "\n",
                "**RRF (Reciprocal Rank Fusion)** combines results:\n",
                "1. Vector search finds semantically similar documents\n",
                "2. Keyword search finds exact matches\n",
                "3. RRF merges and ranks results\n",
                "\n",
                "**Why this matters**: Better recall than vector-only or keyword-only search.\n",
                "\n",
                "### How-To: Build Hybrid Query"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check incident status\n",
                "severity = client.get(b\"incidents/current/severity\")\n",
                "latency = client.get(b\"incidents/current/latency\")\n",
                "error_rate = client.get(b\"incidents/current/error_rate\")\n",
                "\n",
                "if severity and severity.decode() == \"HIGH\":\n",
                "    print(\"üö® INCIDENT DETECTED!\")\n",
                "    print(f\"   Latency: {latency.decode()}ms\")\n",
                "    print(f\"   Error Rate: {error_rate.decode()}%\")\n",
                "    print(f\"\\nüîç Retrieving relevant runbooks...\\n\")\n",
                "    \n",
                "    # Build hybrid query\n",
                "    query = f\"high latency {latency.decode()}ms error rate {error_rate.decode()}%\"\n",
                "    query_embedding = embedding_client.embed(query)\n",
                "    \n",
                "    ns = client.namespace(\"incident_ops\")\n",
                "    collection = ns.collection(\"runbooks\")\n",
                "    \n",
                "    ctx = (\n",
                "        ContextQuery(collection)\n",
                "        .add_vector_query(query_embedding, weight=0.6)  # Semantic similarity\n",
                "        .add_keyword_query(\"latency deployment rollback\", weight=0.4)  # Keyword match\n",
                "        .with_token_budget(2000)\n",
                "        .with_deduplication(DeduplicationStrategy.SEMANTIC)\n",
                "        .execute()\n",
                "    )\n",
                "    \n",
                "    print(f\"üìÑ Retrieved {len(ctx.documents)} relevant runbooks:\")\n",
                "    for i, doc in enumerate(ctx.documents, 1):\n",
                "        print(f\"\\n   {i}. {doc.text}\")\n",
                "        print(f\"      Source: {doc.metadata.get('source', 'unknown')}\")\n",
                "else:\n",
                "    print(\"‚úÖ No incident detected. System healthy.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 5: Generate Mitigation Plan"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if severity and severity.decode() == \"HIGH\":\n",
                "    llm = LLMClient()\n",
                "    \n",
                "    system_message = \"\"\"You are an incident commander. Analyze metrics and runbook guidance.\n",
                "Suggest concrete mitigation actions in priority order.\"\"\"\n",
                "    \n",
                "    prompt = f\"\"\"Incident Details:\n",
                "- Latency P99: {latency.decode()}ms (threshold: 1000ms)\n",
                "- Error Rate: {error_rate.decode()}% (threshold: 5%)\n",
                "\n",
                "Relevant Runbooks:\n",
                "{ctx.as_markdown()}\n",
                "\n",
                "Provide:\n",
                "1. Most likely root cause\n",
                "2. Immediate mitigation actions (priority order)\n",
                "3. Next steps after mitigation\n",
                "\"\"\"\n",
                "    \n",
                "    response = llm.complete(prompt, system_message=system_message)\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "    print(\"MITIGATION PLAN\")\n",
                "    print(\"=\"*70)\n",
                "    print(response)\n",
                "    print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 6: Manage Incident State with ACID\n",
                "\n",
                "### üìö Concept: State Machine Transitions\n",
                "\n",
                "Incident lifecycle:\n",
                "```\n",
                "NONE ‚Üí OPEN ‚Üí MITIGATING ‚Üí RESOLVED\n",
                "```\n",
                "\n",
                "Each transition is atomic:\n",
                "- Update state\n",
                "- Record timestamp\n",
                "- Log to history\n",
                "\n",
                "**All or nothing** - guaranteed consistent.\n",
                "\n",
                "### How-To: Update State Atomically"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def update_incident_state(client, state, details):\n",
                "    \"\"\"Update incident state with atomic writes.\"\"\"\n",
                "    timestamp = datetime.now().isoformat()\n",
                "    \n",
                "    # All 3 writes are atomic in IPC mode\n",
                "    client.put(b\"incidents/current/state\", state.encode())\n",
                "    client.put(b\"incidents/current/last_update\", timestamp.encode())\n",
                "    client.put(f\"incidents/history/{timestamp}\".encode(), f\"{state}: {details}\".encode())\n",
                "    \n",
                "    print(f\"üìù State transition ‚Üí {state}\")\n",
                "    print(f\"   Timestamp: {timestamp}\")\n",
                "    print(f\"   Details: {details}\")\n",
                "\n",
                "# Transition through states\n",
                "if severity and severity.decode() == \"HIGH\":\n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "    print(\"INCIDENT STATE MANAGEMENT\")\n",
                "    print(\"=\"*70 + \"\\n\")\n",
                "    \n",
                "    update_incident_state(client, \"OPEN\", \"Incident detected, analyzing...\")\n",
                "    time.sleep(1)\n",
                "    \n",
                "    update_incident_state(client, \"MITIGATING\", \"Executing rollback procedure\")\n",
                "    time.sleep(1)\n",
                "    \n",
                "    update_incident_state(client, \"RESOLVED\", \"Metrics returned to normal\")\n",
                "    \n",
                "    # Clear incident\n",
                "    client.put(b\"incidents/current/severity\", b\"NONE\")\n",
                "    \n",
                "    print(\"\\n‚úÖ Incident resolved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 7: Verify State History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üìö Incident History:\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# In real implementation, you'd list keys with prefix\n",
                "# For this demo, we'll check current state\n",
                "current_state = client.get(b\"incidents/current/state\")\n",
                "last_update = client.get(b\"incidents/current/last_update\")\n",
                "severity = client.get(b\"incidents/current/severity\")\n",
                "\n",
                "print(f\"Current State: {current_state.decode() if current_state else 'NONE'}\")\n",
                "print(f\"Last Update: {last_update.decode() if last_update else 'N/A'}\")\n",
                "print(f\"Severity: {severity.decode() if severity else 'NONE'}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Understanding Multi-Process Coordination\n",
                "\n",
                "### üí° Key Insight: Shared State Without Message Passing\n",
                "\n",
                "In this demo, we simulated 3 processes in one notebook. In production:\n",
                "\n",
                "**Process A (Collector)**:\n",
                "```python\n",
                "while True:\n",
                "    metrics = get_metrics()\n",
                "    client.put(b\"metrics/latest/...\", metrics)\n",
                "    time.sleep(5)\n",
                "```\n",
                "\n",
                "**Process B (Indexer)**:\n",
                "```python\n",
                "for runbook in watch_directory():\n",
                "    embedding = embed(runbook)\n",
                "    collection.add_document(...)\n",
                "```\n",
                "\n",
                "**Process C (Commander)**:\n",
                "```python\n",
                "while True:\n",
                "    metrics = client.get(b\"metrics/latest/...\")\n",
                "    if is_incident(metrics):\n",
                "        runbooks = query_collection(...)\n",
                "        plan = generate_plan(runbooks)\n",
                "        update_state(\"MITIGATING\")\n",
                "```\n",
                "\n",
                "**No RabbitMQ, Kafka, or Redis Pub/Sub needed!**\n",
                "\n",
                "All processes read/write the same SochDB instance. State is automatically shared.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary: What We Accomplished\n",
                "\n",
                "### ‚úÖ Features Demonstrated\n",
                "\n",
                "1. **IPC Mode** - Connected to SochDB server via Unix socket  \n",
                "2. **Shared State** - Multiple \"processes\" accessing same data\n",
                "3. **Namespaces** - Isolated `incident_ops` namespace\n",
                "4. **Hybrid Retrieval** - Combined vector (0.6) + keyword (0.4) search\n",
                "5. **Token Budgeting** - Retrieved runbooks under 2000 token limit\n",
                "6. **State Machine** - ACID transitions (NONE ‚Üí OPEN ‚Üí MITIGATING ‚Üí RESOLVED)\n",
                "\n",
                "### üí° Key Insights\n",
                "\n",
                "**No Message Queue Needed**\n",
                "- Traditional: Process A ‚Üí Kafka ‚Üí Process B ‚Üí Redis ‚Üí Process C\n",
                "- SochDB: All processes read/write shared database\n",
                "\n",
                "**Automatic Consistency**\n",
                "- ACID guarantees across all processes\n",
                "- No eventual consistency issues\n",
                "- No manual synchronization\n",
                "\n",
                "**Hybrid Search Works Better**\n",
                "- Vector-only: Misses exact keyword matches\n",
                "- Keyword-only: Misses semantic similarity\n",
                "- Hybrid with RRF: Best of both worlds\n",
                "\n",
                "### üöÄ Next Steps\n",
                "\n",
                "Run the actual multi-process demo:\n",
                "```bash\n",
                "cd ../2_incident_response\n",
                "./run_demo.sh\n",
                "```\n",
                "\n",
                "Watch 3 separate processes coordinate through shared SochDB.\n",
                "\n",
                "Try modifying:\n",
                "- Add more runbooks and see hybrid search adapt\n",
                "- Change weights (vector vs keyword)\n",
                "- Add more metrics to trigger different incidents\n",
                "- Implement more complex state machines\n",
                "\n",
                "---\n",
                "\n",
                "## Resources\n",
                "\n",
                "- [SochDB Documentation](https://github.com/sochdb/sochdb)\n",
                "- [IPC Mode Guide](https://github.com/sochdb/sochdb-python-sdk)\n",
                "- [Demo Source Code](../2_incident_response/)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}